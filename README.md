# newsClassifier
A fake news classifier based on semantics analysis

Hexbridge Marshall Wace challenge 

Team twH1uxEQ, Bot that detects and reports disinformation on social media platforms

News classifier Optimised On SEmantics analysis (NOOSE)

We have built a working model of a classifier that can predict fake news. It does this by looking at the semantics of the news article. 
Our dataset was taken from kaggle https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset

We theorise that the semantics of a fake news article will be different from a real news articles, where a fake news articles will try to be more
persuasive and attention grabbing while a real news article is more objective or neutral.

On initialising the class Classifier, we generate 6 different transition matrices. 
- One for the title of real news articles (transition based on current state, x1 -> x2 - > x3 -> ...) (1)
- One for the title of fake news articles (transition based on current state, x1 -> x2 - > x3 -> ...) (2)
- One for the body of real news articles (transition based on current state, x1 -> x2 - > x3 -> ...) (3)
- One for the body of fake news articles (transition based on current state, x1 -> x2 - > x3 -> ...) (4)
- One for the body of real news articles (transition based on current state and previous state, x1^x2 -> x3, x2^x3 - > x4, ...) (5)
- One for the body of fake news articles (transition based on current state and previous state, x1^x2 -> x3, x2^x3 - > x4, ...) (6)

The idea is to calculate the probability that an article is fake or real given the list of parts of speech tokens the article contains.
The list of tokens is generated by using the nlp python library nltk

The parts of speech tokens comprise of verbs, nouns, adverbs etc so we are seeing how the transition of these tokens differ in real news compared to fake news.

In order to find probability that an article is fake based on its title, P(fake | x1 -> x2 - > x3 -> ... ) we calculate the probability of our seen transition assuming the article is fake

Based on Bayes rule, P(fake | x1 -> x2 - > x3 -> ... ) = P(fake) * P(x1 -> x2 - > x3 -> ...| fake)/ P(x1 -> x2 - > x3 -> ...). However we want to compare the probability assuming the article is fake against the probability assuming it was real.

P(fake | x1 -> x2 - > x3 -> ... ) = P(fake) * P(x1 -> x2 - > x3 -> ...| fake)/ P(x1 -> x2 - > x3 -> ...) vs P(real| x1 -> x2 - > x3 -> ... ) = P(real) * P(x1 -> x2 - > x3 -> ...| real)/ P(x1 -> x2 - > x3 -> ...)

In order to simplify our calculations, we assume that P(fake) = P(real) and remove P(x1 -> x2 - > x3 -> ...) on both sides since that is just the average of the tranisition matrices.

So, we get P(x1 -> x2 - > x3 -> ...| fake) vs P(x1 -> x2 - > x3 -> ...| real)



Now comes the intresting part. 

At this point we have six values.

- P(title = fake | x1 -> x2 - > x3 -> ...), P(title = real| x1 -> x2 - > x3 -> ...), (we scale these two such that the sum = 1)
- P(body = fake | x1 -> x2 - > x3 -> ...), P(body = real| x1 -> x2 - > x3 -> ...), (we scale these two such that the sum = 1)
- P(body = fake | x1^x2 -> x3, x2^x3 - > x4, ...), P(body = real| x1^x2 -> x3, x2^x3 - > x4, ...) (we scale these two such that the sum = 1).

We could take a majority vote based on the class that each pair gives a higher probability for, but we believe that each pair should be weighted. Therefore we add a gradient boosting classifier to our model.
We also add a 7th and 8th value which is the compound sentiment of the title and the body based on VADER semantics to add a bit more dimensionality. 

So for each article with a title and a body, we generate a vector of length 8 and feed that into our GBC.

When training the classifier, we have to be careful not to have information leakage, where we use a certain body and title to contribute to our transition matrix, and then calculate the vector of length 8 again for that article using said transition matrix.

In order to avoid this, we used cross training which is demonstrated below

We break our training dateset into 10 equal buckets.
 
In each iteration, we use 9 buckets of articles to generate our transition matrices. Using this transition matrix in the last bucket, we are able to get our vector of length 8 for the articles in that remaining bucket. We will be using the vectors to train a gradient boosting classifier later. 

In the first iteration, we are only able to generate vectors for a single bucket of data. By iterating the above step 10 times, we are able to generate a vector for all articles in the training set. We have also avoided information leakage. The idea is similar to cross validation except we get a larger training sample as opposed to validation sample. We can now train our gradient boosting classifier.

The gradient boosting classifier used is from sklearn and the hyperparameters tuned using RandomisedSearchCV and GridSearchCV

Using a training set of 18000 real articles and 18000 fake articles and a test set of 2000 real articles and 2000 fake articles, we get the following results:

                  precision    recall  f1-score   support

               0       0.99      0.99      0.99      2000
               1       0.99      0.99      0.99      2000

        accuracy                           0.99      4000
       macro avg       0.99      0.99      0.99      4000
    weighted avg       0.99      0.99      0.99      4000

Which definetly looks suspicious. On closer inspection, the problem lies more with the data than our model. Other Kagglers have managed to achieve equally high prediction results using this dataset. 
We aim to change the dataset to get a better estimate of how well our model works.

Using a second dataset from https://www.kaggle.com/c/fake-news/data?select=train.csv, we get the following results:

                  precision    recall  f1-score   support
  
               0       0.72      0.86      0.79       700
               1       0.83      0.67      0.74       700
 
        accuracy                           0.77      1400
       macro avg       0.78      0.77      0.76      1400
    weighted avg       0.78      0.77      0.76      1400
 
Which looks more realistic and is a good sign. Out prediction accuracy is a lot better than random and our scores are pretty good. This means that the concept of this classifier can work.

Overall this is just a proof of concept of a machine learning model to classify fake news.  The important thing is that it must be able to classify an article based on the body and title since those are the most important parts.
In due time it will also be possible to extend this by incorporating it into a bot or website.
